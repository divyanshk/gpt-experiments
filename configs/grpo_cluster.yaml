# GRPO Training Configuration - Cluster Mode
# Optimized for multi-GPU cluster training

mode: cluster
output_dir: ./grpo_results_cluster

# Training Hyperparameters
training:
  num_train_epochs: 3
  per_device_train_batch_size: 8
  gradient_accumulation_steps: 2
  learning_rate: 3.0e-5
  warmup_steps: 500

# Logging & Checkpointing
logging:
  logging_steps: 50
  save_steps: 1000
  log_level: passive
  disable_tqdm: false

# Data Loading
data:
  dataloader_num_workers: 4
  remove_unused_columns: false

# Optimization
optimization:
  optim: adamw_torch_fused    # Optimizer: adamw_torch_fused (faster on modern GPUs), adafactor, etc.
  fp16: true
  gradient_checkpointing: true

# GRPO Specific Parameters
grpo:
  generation_batch_size: 16  # Must be divisible by num_generations
  num_generations: 8         # Number of generations per prompt
  beta: 0.01                 # KL penalty coefficient (enables KL tracking)

# LoRA Configuration (optional)
# Note: lora_alpha defaults to 2x the rank if not specified
lora:
  enabled: false
  r: 16                # LoRA rank (smaller = fewer params, less capacity)
  lora_alpha: 32       # Scaling factor (typically 2x rank)
  lora_dropout: 0.05
  target_modules: ["c_attn", "c_proj"]  # GPT-2: auto-detected, can override here
